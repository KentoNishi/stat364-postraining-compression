{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d768c08",
   "metadata": {},
   "source": [
    "# [github.com/KentoNishi/stat364-postraining-compression](https://github.com/KentoNishi/stat364-postraining-compression)\n",
    "\n",
    "By: Kento Nishi\n",
    "\n",
    "---\n",
    "\n",
    "I ran the ALPS method ([Alternating Lagrangian Pruning for Sparsity](https://github.com/mazumder-lab/ALPS)) that Professor Mazumder covered in his slide deck; he did not get to it during class time, due to time constraints. I thought it would be useful for me to play around with it for everyone else in the class to also learn from. The code below downloads the provided data, loads the model, runs ALPS pruning, and saves the outputs.\n",
    "\n",
    "The layer-wise reconstruction objective the paper defines is as follows (pretrained weights $W_0$; calibration inputs/outputs $X,Y$):\n",
    "\n",
    "$\n",
    "\\min_W\\;\\frac12\\lVert XW^\\top - Y\\rVert_F^2\\; +\\;\\frac\\lambda2\\lVert W - W_0\\rVert_F^2\n",
    "\\quad\\text{s.t.}\\quad \\lVert W\\rVert_0 \\le k\n",
    "$\n",
    "\n",
    "ALPS solves this with the ADMM optimizer, and applies it layer-by-layer to reach the target sparsity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dba326",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb65239c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T18:50:33.584393Z",
     "iopub.status.busy": "2026-02-10T18:50:33.584243Z",
     "iopub.status.idle": "2026-02-10T18:50:33.590640Z",
     "shell.execute_reply": "2026-02-10T18:50:33.590124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths and parameters\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_NAME = \"facebook/opt-125m\"\n",
    "SPARSITY = 0.8\n",
    "NSAMPLES = 8\n",
    "\n",
    "MODEL_PATH = Path(\"./hf_cache\")\n",
    "DATA_PATH = Path(\"./data\")\n",
    "RESULTS_PATH = Path(\"./results\")\n",
    "PRUNED_PATH = Path(\"./pruned_models\")\n",
    "\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "PRUNED_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a25099",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4010b2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T18:50:33.592445Z",
     "iopub.status.busy": "2026-02-10T18:50:33.592183Z",
     "iopub.status.idle": "2026-02-10T18:50:36.849515Z",
     "shell.execute_reply": "2026-02-10T18:50:36.848937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download the authors' calibration data\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "zip_url = \"https://www.dropbox.com/scl/fi/6xg1voa7go9x2uds1y2mq/scd_data.zip?rlkey=8bwzshamiyvcvpd146ymkp0vc&dl=1\"\n",
    "zip_path = DATA_PATH / \"scd_data.zip\"\n",
    "\n",
    "if not zip_path.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_path)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(DATA_PATH)\n",
    "\n",
    "nested = DATA_PATH / \"data\"\n",
    "if nested.exists():\n",
    "    DATA_PATH = nested\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15487307",
   "metadata": {},
   "source": [
    "## Run ALPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb758d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T18:50:36.851684Z",
     "iopub.status.busy": "2026-02-10T18:50:36.851405Z",
     "iopub.status.idle": "2026-02-10T18:50:36.856845Z",
     "shell.execute_reply": "2026-02-10T18:50:36.856298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12731"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allow model download (README: set cached=False)\n",
    "from pathlib import Path\n",
    "\n",
    "opt_path = Path(\"ALPS/opt.py\")\n",
    "text = opt_path.read_text()\n",
    "text = text.replace(\"cached = True\", \"cached = False\")\n",
    "opt_path.write_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94f952e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T18:50:36.858460Z",
     "iopub.status.busy": "2026-02-10T18:50:36.858197Z",
     "iopub.status.idle": "2026-02-10T18:53:07.077712Z",
     "shell.execute_reply": "2026-02-10T18:53:07.077113Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kento/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "loading data\n",
      "facebook/opt-125m\n",
      "Starting ...\n",
      "Ready.\n",
      "----\n",
      "0 self_attn.k_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 self_attn.v_proj\n",
      "0 self_attn.q_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 self_attn.out_proj\n",
      "0 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "1 self_attn.k_proj\n",
      "1 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 self_attn.q_proj\n",
      "1 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "2 self_attn.k_proj\n",
      "2 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 self_attn.q_proj\n",
      "2 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "3 self_attn.k_proj\n",
      "3 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 self_attn.q_proj\n",
      "3 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "4 self_attn.k_proj\n",
      "4 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 self_attn.q_proj\n",
      "4 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "5 self_attn.k_proj\n",
      "5 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 self_attn.q_proj\n",
      "5 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "6 self_attn.k_proj\n",
      "6 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 self_attn.q_proj\n",
      "6 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "7 self_attn.k_proj\n",
      "7 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 self_attn.q_proj\n",
      "7 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "8 self_attn.k_proj\n",
      "8 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 self_attn.q_proj\n",
      "8 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "9 self_attn.k_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 self_attn.v_proj\n",
      "9 self_attn.q_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 self_attn.out_proj\n",
      "9 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "10 self_attn.k_proj\n",
      "10 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 self_attn.q_proj\n",
      "10 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "11 self_attn.k_proj\n",
      "11 self_attn.v_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 self_attn.q_proj\n",
      "11 self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 fc1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 fc2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "591.803955078125\n",
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "772.3150634765625\n",
      "loading data\n",
      "facebook/opt-125m\n",
      "Evaluating ...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "250.8695068359375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run ALPS using the authors' script\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "env[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "env[\"HF_DATASETS_OFFLINE\"] = \"0\"\n",
    "env[\"ALPS_SKIP_ZEROSHOT\"] = \"1\"\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"ALPS/opt.py\",\n",
    "    MODEL_NAME,\n",
    "    \"c4\",\n",
    "    \"ALPS\",\n",
    "    str(SPARSITY),\n",
    "    \"--model_path\",\n",
    "    str(MODEL_PATH),\n",
    "    \"--data_path\",\n",
    "    str(DATA_PATH),\n",
    "    \"--nsamples\",\n",
    "    str(NSAMPLES),\n",
    "]\n",
    "\n",
    "subprocess.check_call(cmd, env=env)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}